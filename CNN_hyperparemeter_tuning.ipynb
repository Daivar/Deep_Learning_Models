{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN hyperparemeter tuning.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyO4xJdpTDe/XKaDvr5Vrj7X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Daivar/Deep_Learning_Models/blob/main/CNN_hyperparemeter_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJz1BwgZcR5t"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf ./datasets/images/\n",
        "\n",
        "!wget -q --directory-prefix='datasets/mnist-in-csv/' https://github.com/MindaugasBernatavicius/DeepLearningCourse/raw/master/07_Computer_Vision_Image_Classification/datasets/mnist-in-csv/mnist_test.csv\n",
        "!wget -q --directory-prefix='datasets/mnist-in-csv/' https://github.com/MindaugasBernatavicius/DeepLearningCourse/raw/master/07_Computer_Vision_Image_Classification/datasets/mnist-in-csv/mnist_train.csv"
      ],
      "metadata": {
        "id": "J26PeJuecmw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train = pd.read_csv('datasets/mnist-in-csv/mnist_train.csv')\n",
        "mnist_test = pd.read_csv('datasets/mnist-in-csv/mnist_test.csv')"
      ],
      "metadata": {
        "id": "wHxn9f7scnyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train.head()"
      ],
      "metadata": {
        "id": "My1UWBivcsK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train = mnist_train.dropna()\n",
        "mnist_test = mnist_test.dropna()"
      ],
      "metadata": {
        "id": "L_uqL4rAcxyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_sel = mnist_train.sample(8)\n",
        "random_sel.shape"
      ],
      "metadata": {
        "id": "N-gkVRWMc01F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_features = random_sel.drop('label', axis=1)\n",
        "image_batch = (torch.Tensor(image_features.values / 255.)).reshape((-1, 28, 28))\n",
        "image_batch.shape"
      ],
      "metadata": {
        "id": "UV9QgKBIc2XV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unsqueezed = image_batch.unsqueeze(1)\n",
        "print(unsqueezed.shape) # torch.Size([8, 1, 28, 28]) --> batch size needs to be first dimension, so we add 1 the 2nd dimension\n",
        "grid = torchvision.utils.make_grid(unsqueezed, nrow=8)\n",
        "grid.shape"
      ],
      "metadata": {
        "id": "CvN3GNAPc4_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure (figsize = (12, 12))\n",
        "plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "E3_ZEegcc7s2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(image_batch[0].max())\n",
        "print(image_batch[0].min())"
      ],
      "metadata": {
        "id": "N20I1pPudAxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identifying features and labels\n",
        "\n",
        "mnist_train_features = mnist_train.drop('label', axis =1)\n",
        "mnist_train_target = mnist_train['label']\n",
        "\n",
        "mnist_test_features = mnist_test.drop('label', axis =1)\n",
        "mnist_test_target = mnist_test['label']"
      ],
      "metadata": {
        "id": "wcKXS8lngLpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting to tensors\n",
        "\n",
        "X_train_tensor = torch.tensor(mnist_train_features.values, dtype=torch.float)\n",
        "x_test_tensor  = torch.tensor(mnist_test_features.values, dtype=torch.float) \n",
        "\n",
        "Y_train_tensor = torch.tensor(mnist_train_target.values, dtype=torch.long)\n",
        "y_test_tensor  = torch.tensor(mnist_test_target.values, dtype=torch.long)"
      ],
      "metadata": {
        "id": "yk3ryyaxgTFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_tensor.shape)\n",
        "print(Y_train_tensor.shape)\n",
        "print(x_test_tensor.shape)\n",
        "print(y_test_tensor.shape)"
      ],
      "metadata": {
        "id": "tUhFfHF_gdcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshaping the tensors according to what the CNN needs\n",
        "\n",
        "X_train_tensor = X_train_tensor.reshape(-1, 1, 28, 28)\n",
        "x_test_tensor = x_test_tensor.reshape(-1, 1, 28, 28)\n",
        "\n"
      ],
      "metadata": {
        "id": "NoeNtZ3xget-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_tensor.shape)\n",
        "print(Y_train_tensor.shape)\n",
        "print(x_test_tensor.shape)\n",
        "print(y_test_tensor.shape)"
      ],
      "metadata": {
        "id": "uGhTVX_bgoeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining CNN\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n"
      ],
      "metadata": {
        "id": "3N8Yav7cgtmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuring the neural network\n",
        "# The input size will be the channels of the images (in_size), for RGB it will be 3, for grayscale - 1\n",
        "# The final output will have a size equal to the number of classes for the prediction\n",
        "# The convolving kernel will have a size of k_conv_size\n",
        "# hid1 and hid2 are the kernel counts (i.e. how many feature maps there will be)\n",
        "\n",
        "in_size = 1 # channel size\n",
        "hid1_size = 16 #Re-run for 32\n",
        "hid2_size = 32 #Re-run for 64\n",
        "out_size = 10 # categories\n",
        "k_conv_size = 5 # size of kernel"
      ],
      "metadata": {
        "id": "x9lukQE3gyH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_size, hid1_size, k_conv_size), # 24x24x16\n",
        "            nn.BatchNorm2d(hid1_size),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2)) # 12x12x16\n",
        "        \n",
        "        # hid1_size - is the dimension of the first convolutional layer\n",
        "        # ... so the second layers needs to accept that size: Conv2d(hid1_size, ...)\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(hid1_size, hid2_size, k_conv_size),\n",
        "            nn.BatchNorm2d(hid2_size),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2))\n",
        "        # you can use the formula to calculate this, \n",
        "        # ... or just print our the outputs from the each layer \n",
        "        # ... and see the sizes\n",
        "        self.fc = nn.Linear(512, out_size)\n",
        "        \n",
        " \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        print(out.shape) # torch.Size([55933, 16, 12, 12]) 12x12 the size of feature map produced, 16 is the depth\n",
        "        out = self.layer2(out)\n",
        "        print(out.shape) # torch.Size([55933, 32, 4, 4]) 4x4 the size of feature map produced, 32 is the depth\n",
        "        # reshape for feeding into the FCFFNN\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        print(out.shape) # torch.Size([55933, 512]) 34 * 4 * 4 = 512\n",
        "        out = self.fc(out)\n",
        "        print(out.shape) # torch.Size([55933, 10])\n",
        "        return out\n",
        "        # return F.log_softmax(out, dim=-1) # we will use this latter"
      ],
      "metadata": {
        "id": "rJL0CbPDhJ_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvNet()"
      ],
      "metadata": {
        "id": "JIWEE6oFhaMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "yZn2sjkQhbWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "id": "UTmY69gmhfvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = X_train_tensor.to(device)\n",
        "x_test_tensor  = x_test_tensor.to(device) \n",
        "\n",
        "Y_train_tensor = Y_train_tensor.to(device)\n",
        "y_test_tensor  = y_test_tensor.to(device)"
      ],
      "metadata": {
        "id": "j6NaWxAchiEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Re-run for each different value\n",
        "learning_rate = 0.001 #0.01 \n",
        "criterion = nn.CrossEntropyLoss() # can work with the output of a LinearLayer as well\n",
        "# criterion = nn.NLLLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)   "
      ],
      "metadata": {
        "id": "uTfoylzHhrz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "# %%time\n",
        "num_epochs = 25 # -14 min\n",
        "loss_values = list()\n",
        "\n",
        "# same training loop as before with the FCFFNN\n",
        "for epoch in range(1, num_epochs):   \n",
        "    outputs = model(X_train_tensor)\n",
        "    loss = criterion(outputs,Y_train_tensor)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch - %d, loss - %0.5f '%(epoch, loss.item()))\n",
        "    loss_values.append(loss.item())"
      ],
      "metadata": {
        "id": "jJCaXfW4hs3H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Evaluation\n",
        "\n",
        "x = (range(0, num_epochs-1))\n",
        "\n",
        "plt.figure(figsize = (8, 8))\n",
        "plt.plot(x, loss_values)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')"
      ],
      "metadata": {
        "id": "8NVnALh9iFoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we have batch norm, so we must switch to eval mode\n",
        "# ... to deactivate the batch norm\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "_-echKT0jOAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score"
      ],
      "metadata": {
        "id": "S7bjgcjUjQmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    outputs = model(x_test_tensor)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    \n",
        "    y_test = y_test_tensor.cpu().numpy()\n",
        "    predicted = predicted.cpu()\n",
        "    \n",
        "    print(\"Accuracy: \", accuracy_score(predicted, y_test))\n",
        "    print(\"Precision: \", precision_score(predicted, y_test, average='weighted'))\n",
        "    print(\"Recall: \", recall_score(predicted, y_test, average='weighted'))"
      ],
      "metadata": {
        "id": "Y7oloCSdjTuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"sample target data = \", mnist_test_target.values[1005])"
      ],
      "metadata": {
        "id": "pfsNr7Xwy-hG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_img = mnist_test_features.values[1005]\n",
        "sample_img = sample_img.reshape(1, 28, 28)\n",
        "\n",
        "sample_img = sample_img[0, :, :]\n",
        "\n",
        "plt.figure(figsize =(6, 6))\n",
        "plt.imshow(sample_img)"
      ],
      "metadata": {
        "id": "AoBaZFNXzB1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = np.array(mnist_test_features.values[1005]) \n",
        "\n",
        "sample_tensor = torch.from_numpy(sample).float()\n",
        "sample_tensor = sample_tensor.reshape(-1, 1, 28, 28)\n",
        "sample_tensor = sample_tensor.to(device)"
      ],
      "metadata": {
        "id": "VAEB1wPwzGvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model(sample_tensor)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "9Ng4ikHnzJvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, predicted = torch.max(y_pred.data, -1)\n",
        "print (\" The predicted label is : \", predicted.item())"
      ],
      "metadata": {
        "id": "3wToafQvzPPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q --directory-prefix='./' https://github.com/MindaugasBernatavicius/DeepLearningCourse/raw/master/07_Computer_Vision_Image_Classification/datasets/cust_img_of_3.jpg\n",
        "!wget -q --directory-prefix='./' https://github.com/MindaugasBernatavicius/DeepLearningCourse/raw/master/07_Computer_Vision_Image_Classification/datasets/cust_img_of_1.jpg"
      ],
      "metadata": {
        "id": "PICIyN03zUHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import PIL.ImageOps\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.transform\n",
        "import skimage.io\n",
        "from skimage import data\n",
        "\n",
        "image_name = \"cust_img_of_3.jpg\"\n",
        "image = mpimg.imread(image_name)\n",
        "plt.title(\"Original Image\")\n",
        "plt.imshow(image) "
      ],
      "metadata": {
        "id": "-LRDQqOIzYFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_image = Image.open(image_name)\n",
        "resized_image = original_image.resize((28, 28))\n",
        "\n",
        "plt.title(\"Original Image\")\n",
        "plt.imshow(resized_image)"
      ],
      "metadata": {
        "id": "XZYaQwL5zf1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gray_image = skimage.color.rgb2gray(np.asarray(resized_image))\n",
        "plt.imshow(gray_image, cmap='gray')\n",
        "gray_image.shape"
      ],
      "metadata": {
        "id": "4UHFJkH3zjfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inverted_image = PIL.ImageOps.invert(resized_image)\n",
        "gray_image = skimage.color.rgb2gray(np.asarray(inverted_image))\n",
        "plt.imshow(gray_image, cmap='gray')"
      ],
      "metadata": {
        "id": "oedCzs4lzpgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_tensor = torch.from_numpy(gray_image).float()\n",
        "sample_tensor = image_tensor.reshape(-1, 1, 28, 28)\n",
        "sample_tensor = sample_tensor.to(device)\n",
        "y_pred = model(sample_tensor)\n",
        "y_pred"
      ],
      "metadata": {
        "id": "x40oCi-00GyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, predicted = torch.max(y_pred.data, -1) # the max of the prediction will be the final answer\n",
        "print(\"The predicted label is : \", predicted.item())"
      ],
      "metadata": {
        "id": "VV0q10ko0KGF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's verify this hypothesis\n",
        "for line in gray_image:\n",
        "  for pixel in line:\n",
        "    pixel = 1 if pixel > 0.1 else 0\n",
        "    print(str(pixel).rjust(2, ' '), end='')\n",
        "    # print(str(round(pixel, 2)).rjust(3, ' '), end='') # the old way does not qiute work\n",
        "  print()"
      ],
      "metadata": {
        "id": "OpK_3QVIzyVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image, ImageEnhance \n",
        "\n",
        "im = Image.open(image_name)\n",
        "resized_image = im.resize((28, 28))\n",
        "inverted = PIL.ImageOps.invert(resized_image)\n",
        "enhancer = ImageEnhance.Contrast(inverted)\n",
        "enhanced_im = enhancer.enhance(1.5) # 0.9\n",
        "gray_image = skimage.color.rgb2gray(np.asarray(enhanced_im))\n",
        "\n",
        "def increase_whites_by_threshold(img, threshold):\n",
        "  for line in range(0, len(img)):\n",
        "    for pixel in range(0, len(img[line])):\n",
        "      img[line][pixel] = 1 if img[line][pixel] > threshold else 0\n",
        "\n",
        "increase_whites_by_threshold(gray_image, 0.2)\n",
        "plt.imshow(gray_image, cmap='gray')"
      ],
      "metadata": {
        "id": "r72G-_iM3BVU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}