{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMnxLk3bvfRyDnHW+4ouC5f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Daivar/Deep_Learning_Models/blob/main/Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "7V9Ql1BnjUag",
        "outputId": "60e9ff6a-dbe9-420f-9f7b-c93cfaa58ec5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 13255764395325002547\n",
            "xla_global_id: -1\n",
            "]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "[name: \"/device:CPU:0\"\ndevice_type: \"CPU\"\nmemory_limit: 268435456\nlocality {\n}\nincarnation: 18109656311390607226\nxla_global_id: -1\n]",
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# import and suppres warnings \n",
        "# ... (if you don't want to suppress them, you need to match the numpy version)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "from IPython.display import Markdown, display\n",
        "import tensorflow as tf\n",
        "tf.__version__\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "print(str(device_lib.list_local_devices()))\n",
        "display(Markdown(str(device_lib.list_local_devices())))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eP2PcJqMAkVt",
        "outputId": "bb7d5fd4-ecb4-4eb7-dd8b-f3d69ddff626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.7.0'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    # verify that the math works\n",
        "    a = tf.constant(50)\n",
        "    b = tf.constant(51)\n",
        "    print(\"a + b = {0}\".format(sess.run(a + b)))\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGd3jiunlmxt",
        "outputId": "eb0d4d44-43e3-4240-d0d7-a1d1e354bc5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a + b = 101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "a1 = np.array([5, 3, 8])\n",
        "b1 = np.array([3, -1, 2])\n",
        "c1 = a1 + b1\n",
        "print(c1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGN-blzkFjQ0",
        "outputId": "94dad7dd-45f9-4b2c-cef5-746f4a07173e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 8  2 10]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K51TEn2lEo3q"
      },
      "source": [
        "a = tf.compat.v1.placeholder(dtype = tf.int32, shape = [None])  \n",
        "b = tf.compat.v1.placeholder(dtype = tf.int32, shape = [None])\n",
        "c = tf.add(x = a, y = b)\n",
        "\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    result = sess.run(fetches = c, feed_dict = {\n",
        "        a: [3, 4, 5],\n",
        "        b: [-1, 2, 3]\n",
        "    })\n",
        "    print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# restart notebook before running\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "# Define a Python function\n",
        "def function_to_get_faster(x, y, b):\n",
        "  x = tf.matmul(x, y)\n",
        "  x = x + b\n",
        "  return x\n",
        "\n",
        "# Create a `Function` object that contains a graph\n",
        "a_function_that_uses_a_graph = tf.function(function_to_get_faster)\n",
        "\n",
        "# Make some tensors\n",
        "x1 = tf.constant([[1.0, 2.0]])\n",
        "y1 = tf.constant([[2.0], [3.0]])\n",
        "b1 = tf.constant(4.0)\n",
        "\n",
        "# It just works!\n",
        "a_function_that_uses_a_graph(x1, y1, b1).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fC3X34oFFskj",
        "outputId": "b6f07efc-f44a-436a-cd61-4829eb36786f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# restart notebook before running\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.executing_eagerly()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUf0IxwnGdji",
        "outputId": "67ac60ff-6ffb-40f7-cf09-cdaeea883b8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = [[2.]]\n",
        "m = tf.matmul(x, x)\n",
        "print(\"Result: {}\".format(m))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rj4hRnPXGfiC",
        "outputId": "c83c8996-f11e-4035-9e03-e5834653c2af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result: [[4.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# define number of training samples, 0.7 = 70%.  \n",
        "# We can take the first 70% since the values are randomized\n",
        "num_train_samples = math.floor(num_house * 0.7)\n",
        "\n",
        "# define training data\n",
        "train_house_size = np.asarray(house_sizes[:num_train_samples])\n",
        "train_price = np.asanyarray(house_prices[:num_train_samples:])\n",
        "\n",
        "train_house_size_norm = normalize(train_house_size)\n",
        "train_price_norm = normalize(train_price)\n",
        "\n",
        "# define test data\n",
        "test_house_size = np.array(house_sizes[num_train_samples:])\n",
        "test_house_price = np.array(house_prices[num_train_samples:])\n",
        "\n",
        "test_house_size_norm = normalize(test_house_size)\n",
        "test_house_price_norm = normalize(test_house_price)\n",
        "\n",
        "#  Variables that get updated as we descend down the gradient\n",
        "tf_house_size = 0.0 \n",
        "tf_price = 0.0"
      ],
      "metadata": {
        "id": "k0gwNhKWN-QP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearModel:\n",
        "    def __call__(self, x):\n",
        "        # 2. Define the operations for the predicting values. We are using the TF API for addition and mult\n",
        "        return tf.add(tf.multiply(self.Weight, x), self.Bias) # could use: self.Weight * x + self.Bias # mx + b\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.Weight = tf.Variable(11.0)\n",
        "        self.Bias = tf.Variable(12.0)\n",
        "\n",
        "def loss(y, pred): \n",
        "    # 3. Define the Loss Function RMSE \n",
        "    return tf.reduce_mean(tf.square(y - pred)) # y - pred, but since we are are doing batch procesing, we need more complex error functions\n",
        "\n",
        "# Optimizer learning rate. The size of the steps down the gradient\n",
        "def train(linear_model, x, y, lr=0.12):\n",
        "    with tf.GradientTape() as t:\n",
        "        # loss(y, mx + b) , the second term calls the __call__() method,\n",
        "        # which is just simply the regresion formula\n",
        "        current_loss = loss(y, linear_model(x))\n",
        "\n",
        "    # 4. define a Gradient descent optimizer that will minimize the loss defined in the operation \"cost\".\n",
        "    lr_weight, lr_bias = t.gradient(current_loss, [linear_model.Weight, linear_model.Bias])\n",
        "    linear_model.Weight.assign_sub(lr * lr_weight)\n",
        "    linear_model.Bias.assign_sub(lr * lr_bias)\n",
        "\n",
        "\n",
        "linear_model = LinearModel()\n",
        "Weights, Biases = [], []\n",
        "epochs = 30\n",
        "for epoch_count in range(epochs):\n",
        "    Weights.append(linear_model.Weight.numpy()) \n",
        "    Biases.append(linear_model.Bias.numpy())\n",
        "    real_loss = loss(train_price_norm, linear_model(train_house_size_norm)) # expectation - predictioon\n",
        "    train(linear_model, train_house_size_norm, train_price_norm, lr=0.11)\n",
        "    print(f\"Epoch count {epoch_count}: Loss value: {real_loss.numpy()}\")"
      ],
      "metadata": {
        "id": "Gr-mzFnfOH9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot\n",
        "train_house_size_mean = train_house_size.mean()\n",
        "train_house_size_std = train_house_size.std()\n",
        "\n",
        "train_price_mean = house_prices.mean()\n",
        "train_price_std = house_prices.std()\n",
        "\n",
        "plt.plot(train_house_size, train_price, \"bx\")  # bx = blue x\n",
        "# plot the predicted line\n",
        "plt.plot(train_house_size_norm * train_house_size_std + train_house_size_mean, linear_model(train_house_size_norm) * train_price_std + train_price_mean , '--m')\n",
        "plt.ylabel(\"Price\")\n",
        "plt.xlabel(\"Size\")\n",
        "plt.show()\n",
        "\n",
        "# predict\n",
        "print(f\"Epoch count {epoch_count}: Loss value: {real_loss.numpy()}\")"
      ],
      "metadata": {
        "id": "AEN2hizVOVob"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}