{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pytorch_regresion_bike_sharing.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOV4H0bswbYBNlG17kZlyW4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Daivar/Deep_Learning_Models/blob/main/Pytorch_regresion_bike_sharing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multiple regression w/ Pytorch"
      ],
      "metadata": {
        "id": "HBoYH3wOoP4T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem statement\n",
        "Given data counting bike sharing statistics, predict future demand for bikes.\n",
        "\n",
        "Bike sharing systems are a new generation of traditional bike rentals where the whole process from membership, rental and return back has become automatic. Through these systems, user is able to easily rent a bike from a particular position and return back to another position. Currently, there are about over 500 bike-sharing programs around the world which are composed of over 500 thousands bicycles. Today, there exists great interest in these systems due to their important role in traffic, environmental and health issues.\n",
        "\n",
        "Apart from interesting real-world applications of bike sharing systems, the characteristics of data being generated by these systems make them attractive for the research. Opposed to other transport services such as bus or subway, the duration of travel, departure and arrival position is explicitly recorded in these systems. This feature turns bike sharing system into a virtual sensor network that can be used for sensing mobility in the city. Hence, it is expected that most of important events in the city could be detected via monitoring these data.\n",
        "\n",
        "This dataset contains the hourly and daily count of rental bikes between years 2011 and 2012 in Capital bikeshare system in Washington, DC with the corresponding weather and seasonal information.\n",
        "\n",
        "https://www.kaggle.com/marklvl/bike-sharing-dataset"
      ],
      "metadata": {
        "id": "YfEIs_E2oXle"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9lviEMbSodfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install graphviz\n",
        "!pip install hiddenlayer"
      ],
      "metadata": {
        "id": "Rh-Cb7Tnon3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import hiddenlayer as hl\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sklearn"
      ],
      "metadata": {
        "id": "hIT0V3dsoq6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.kaggle.com/marklvl/bike-sharing-dataset\n",
        "# !wget https://www.kaggle.com/marklvl/bike-sharing-dataset/download -O data.zip # need to add auth data\n",
        "!wget https://github.com/MindaugasBernatavicius/DeepLearningCourse/raw/master/06_Regression_with_Neural_Networks_and_Tabular_Data/28865_36778_bundle_archive.zip \n",
        "\n",
        "\n",
        "!unzip -n *archive.zip\n",
        "# !rm -rf bike-sharing-dataset/\n",
        "!rm -f *.txt *.csv\n",
        "!rm -f my_model"
      ],
      "metadata": {
        "id": "CvHw51pAoxIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('./bike-sharing-dataset/hour.csv', index_col=0)"
      ],
      "metadata": {
        "id": "XksJrIJUo3-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "jPB6DXHPo8z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reversing the ordinal encoding"
      ],
      "metadata": {
        "id": "vIpJQ4VXpJ7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"season\"].replace({1: \"spring\", 2: \"summer\", 3: \"fall\", 4: \"winter\"}, inplace=True)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "fwtgxSYkpCqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "3ibI5CP4pTdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing relationships\n",
        "We see that for both the years fall is the most popular season for bike rentals.\n",
        "The Bike rentals seem to have increased in one year"
      ],
      "metadata": {
        "id": "Fs_4hJCYpakM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "sns.barplot('yr', 'cnt', hue = 'season', data = data, ci=None)\n",
        "plt.legend(loc = 'upper right', bbox_to_anchor=(1.2,0.5))\n",
        "\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Total number of bikes rented')\n",
        "\n",
        "plt.title('Number of bikes rented per season')"
      ],
      "metadata": {
        "id": "PiNRKUuSpcY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "workingday: If day is neither weekend nor holiday is 1, otherwise is 0\n",
        "we see that when it is not a working day more bikes are rented for all months"
      ],
      "metadata": {
        "id": "P_Mwj9ncppJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "sns.barplot(x = 'mnth', y = 'cnt', hue = 'workingday', data = data)\n",
        "\n",
        "plt.title('Number of bikes rented per month')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3O7dIvSHpqR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "number of bikes rented are higher for high temperature"
      ],
      "metadata": {
        "id": "CEu7YisLpuxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "fig = sns.scatterplot(x = 'temp', y = 'cnt', data = data)\n",
        "\n",
        "plt.xlabel('Temperature')\n",
        "plt.ylabel('Total number of bikes rented')"
      ],
      "metadata": {
        "id": "UcxiG07Opykg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "sns.heatmap(data.corr(), annot=True, linewidths=0.05, fmt= '.2f')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IIWB1wSFp5VJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### One-hot encoding on season"
      ],
      "metadata": {
        "id": "HXff-OJmp_q-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.sample(5)"
      ],
      "metadata": {
        "id": "vtBt7gN5qBpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.get_dummies(data, columns= ['season'])"
      ],
      "metadata": {
        "id": "SrXnydQvqLv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.sample(5)"
      ],
      "metadata": {
        "id": "LAJjkDMkqQH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Choose features"
      ],
      "metadata": {
        "id": "TrMYCACJqXmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns = ['registered', 'holiday', 'weekday', \n",
        "           'weathersit', 'temp', 'atemp',\n",
        "           'season_fall', 'season_spring', \n",
        "           'season_summer', 'season_winter']\n",
        "\n",
        "features = data[columns]"
      ],
      "metadata": {
        "id": "4Wa6e6pGrtWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features.head()"
      ],
      "metadata": {
        "id": "ZPpdH81orufK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = data[['cnt']]"
      ],
      "metadata": {
        "id": "K96uOCFWqlyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target.head()"
      ],
      "metadata": {
        "id": "haf1_lgeqZDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, x_test, Y_train, y_test = train_test_split(features, target, test_size=0.2)"
      ],
      "metadata": {
        "id": "zIJscZziq2Lx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.tensor(X_train.values, dtype = torch.float)\n",
        "x_test_tensor = torch.tensor(x_test.values, dtype = torch.float)\n",
        "\n",
        "Y_train_tensor = torch.tensor(Y_train.values, dtype = torch.float)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype = torch.float)"
      ],
      "metadata": {
        "id": "4Eo890PerihA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor.shape"
      ],
      "metadata": {
        "id": "L2F9ih4Ir5kg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_tensor.shape"
      ],
      "metadata": {
        "id": "fSEms2Lhr7id"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.utils.data as data_utils "
      ],
      "metadata": {
        "id": "lo4eX-4or_SA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### torch.utils.data.TensorDataset(*tensors) - Dataset wrapping tensors.Each sample will be retrieved by indexing tensors along the first dimension."
      ],
      "metadata": {
        "id": "1cdbZmo_sDJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = data_utils.TensorDataset(X_train_tensor, Y_train_tensor)"
      ],
      "metadata": {
        "id": "NbHREqXesIJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## torch.utils.data.DataLoader - combines a dataset and a sampler, and provides single or multi-process iterators over the dataset.\n",
        "\n",
        "torch.utils.data.DataLoader provides\n",
        "\n",
        "Batching the data\n",
        "Shuffling the data\n",
        "Load the data in parallel using multiprocessing workers"
      ],
      "metadata": {
        "id": "SnpXjeL0sP9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = data_utils.DataLoader(train_data, batch_size=1000, shuffle=True)"
      ],
      "metadata": {
        "id": "dTH9I2ihsL0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loader)"
      ],
      "metadata": {
        "id": "YAenP1elsem8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_batch, target_batch = iter(train_loader).next()"
      ],
      "metadata": {
        "id": "qBWKgRa1sgSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_batch.shape"
      ],
      "metadata": {
        "id": "uLxjuDUtsoIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_batch.shape"
      ],
      "metadata": {
        "id": "P6hT8kDNspvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## If it's a time series data, why can we just split it like that? We know that train_test_split() produces a random split, however while splitting like this we simply subdivide the data randomly and the pattern of bike shares increasing \"as the days go by\" is still there.\n",
        "\n",
        "More concretelly we would be training a time series model with data missing. This is not ideal (that is why we ommited date dimension) and is a topic worthy of separate discusion which would be centered around \"dealing with time series data\", \"splitting time series data\", \"time based cross validation\", \"rolling window analysis\", etc.\n",
        "\n",
        "https://stats.stackexchange.com/questions/117350/how-to-split-dataset-for-time-series-prediction\n",
        "\n",
        "https://towardsdatascience.com/time-based-cross-validation-d259b13d42b8"
      ],
      "metadata": {
        "id": "7Oj0HAH7stMY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NM Definition\n",
        "Define the parameters for the neural network\n",
        "inp sets the input size matching the shape of the X_train_tensor.\n",
        "out will be used to set the size of the output from the neural network. We only predict a single output for each day, so this will be 1\n",
        "hid is used to set the number of hidden neurons in our neural network\n",
        "loss_fn is MSELoss since we're performing a linear regression"
      ],
      "metadata": {
        "id": "2svzET4Cs-jY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inp = X_train_tensor.shape[1]\n",
        "out = 1\n",
        "\n",
        "hid = 10\n",
        "\n",
        "loss_fn = torch.nn.MSELoss()"
      ],
      "metadata": {
        "id": "eyOs92g6s1AB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### nn.Sequential: Use the nn package to define our model as a sequence of layers. nn.Sequential is a Module which contains other Modules, and applies them in sequence to produce its output. Each Linear Module computes output from input using a linear function, and holds internal Tensors for its weight and bias.\n",
        "\n",
        "nn.Linear: Applies a linear transformation to the incoming data: y=Ax+b\n",
        "parameters:\n",
        "in_features – size of each input sample out_features – size of each output sample bias – If set to False, the layer will not learn an additive bias. Default: True\n",
        "\n",
        "Sigmoid : Applies the element-wise function Sigmoid(x)= 1 / (1+exp(−x))\n",
        "\n",
        "Dropout : During training, randomly zeroes some of the elements of the input tensor with probability p using samples from a Bernoulli distribution. Each channel will be zeroed out independently on every forward call."
      ],
      "metadata": {
        "id": "ZYpFykLjtHDH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating model using nn.Sequential\n",
        "Steps:\n",
        "\n",
        "first run only with two linear layer\n",
        "then run ReLU linear\n",
        "then use dropout with all the layers to regularise the model"
      ],
      "metadata": {
        "id": "Ik-W4nD9tTfS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Linear layers are enough for this problem."
      ],
      "metadata": {
        "id": "7-VfObe1tckQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = torch.nn.Sequential(torch.nn.Linear(inp, hid),\n",
        "#                             torch.nn.Linear(hid, out))\n",
        "\n",
        "# model = torch.nn.Sequential(torch.nn.Linear(inp, hid),\n",
        "#                             torch.nn.ReLU(),\n",
        "#                             torch.nn.Linear(hid, out))\n",
        "\n",
        "model = torch.nn.Sequential(torch.nn.Linear(inp, hid),\n",
        "                            torch.nn.ReLU(),\n",
        "                            torch.nn.Dropout(p=0.2),\n",
        "                            torch.nn.Linear(hid, out))\n",
        "\n",
        "# model = torch.nn.Sequential(torch.nn.Linear(inp, hid),\n",
        "#                             torch.nn.Sigmoid(),\n",
        "#                             torch.nn.Linear(hid, out))"
      ],
      "metadata": {
        "id": "Vy2S-txvthiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = torch.nn.Sequential(torch.nn.Linear(inp, hid),\n",
        "#                             torch.nn.Linear(hid, out))\n",
        "\n",
        "model = torch.nn.Sequential(torch.nn.Linear(inp, hid),\n",
        "                            torch.nn.ReLU(),\n",
        "                            torch.nn.Linear(hid, out))\n",
        "\n",
        "# model = torch.nn.Sequential(torch.nn.Linear(inp, hid),\n",
        "#                            torch.nn.ReLU(),\n",
        "#                           torch.nn.Dropout(p=0.2),\n",
        "#                            torch.nn.Linear(hid, out))\n",
        "\n",
        "# model = torch.nn.Sequential(torch.nn.Linear(inp, hid),\n",
        "#                             torch.nn.Sigmoid(),\n",
        "#                             torch.nn.Linear(hid, out))"
      ],
      "metadata": {
        "id": "s0ms_fOTwR0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hl.build_graph(model, torch.zeros([10, inp]))"
      ],
      "metadata": {
        "id": "iemxcETDtlBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
      ],
      "metadata": {
        "id": "t0w3RXDntxYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training our model\n",
        "Foward Pass:\n",
        "\n",
        "Pred# icting Y with input data X\n",
        "# Finding Loss:\n",
        "\n",
        "# Finding difference between Y_train_tensor(target) and output using MSEloss # function defined above\n",
        "Back Propagation:\n",
        "\n",
        "starting with zero gradients before back propogation\n",
        "back propogation is done by simply loss.backward() function\n",
        "optimizer step\n",
        "\n",
        "All optimizers implement a step() method, that updates the parameters.\n",
        "reducing weight with multiple of learning rate and gradient"
      ],
      "metadata": {
        "id": "jL5CH6kot3WX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_step = len(train_loader)\n",
        "print(total_step)"
      ],
      "metadata": {
        "id": "Ov002bzit40Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "\n",
        "for epoch in range(num_epochs + 1):\n",
        "    for i, (features, target) in enumerate(train_loader):\n",
        "        output = model(features)\n",
        "        loss = loss_fn(output, target)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if epoch % 10 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "metadata": {
        "id": "NYAQxYm3t-nZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_pred = model(x_test_tensor)"
      ],
      "metadata": {
        "id": "ba5DQlqEuaTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = x_test.iloc[41]\n",
        "sample"
      ],
      "metadata": {
        "id": "6_NeMQq-ubeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_tensor = torch.tensor(sample.values, dtype = torch.float)\n",
        "sample_tensor"
      ],
      "metadata": {
        "id": "4clI-r4juffT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    y_pred = model(sample_tensor)\n",
        "\n",
        "print(\"Predicted count : \", (y_pred.item()))\n",
        "print(\"Actual count : \", (y_test.iloc[41]))"
      ],
      "metadata": {
        "id": "IKYxVao6ulmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    y_pred_tensor = model(x_test_tensor)"
      ],
      "metadata": {
        "id": "0xSMAQahuo4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = y_pred_tensor.detach().numpy()\n",
        "y_pred.shape"
      ],
      "metadata": {
        "id": "JzA_45TuusPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test.values.shape"
      ],
      "metadata": {
        "id": "Oy8ucpu-us1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_df = pd.DataFrame({'actual': np.squeeze(y_test.values), 'predicted': np.squeeze(y_pred)})\n",
        "\n",
        "compare_df.sample(20)"
      ],
      "metadata": {
        "id": "yzqtpypCuzhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "print(sklearn.metrics.r2_score(y_test, y_pred))\n",
        "print(mean_absolute_error(y_test, y_pred))\n",
        "\n",
        "# L -> L\n",
        "# 0.947522541648828\n",
        "# 24.4707706184464\n",
        "\n",
        "# L w/ Relu -> L\n",
        "# 0.9489632905556128\n",
        "# 23.006869639502572\n",
        "\n",
        "# L w/ Relu -> L\n",
        "# 0.939177669114976\n",
        "# 22.81379715507149"
      ],
      "metadata": {
        "id": "A0RqK_wYu06B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "\n",
        "plt.scatter(y_pred, y_test.values, s=20)\n",
        "\n",
        "plt.xlabel(\"Actual count\")\n",
        "plt.ylabel(\"Predicted count\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JX2gsAzDu6hG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(900, 20))\n",
        "\n",
        "plt.plot(y_pred, label='Predicted count')\n",
        "plt.plot(y_test.values, label='Actual count')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SIW6hkRjvs_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'my_model')"
      ],
      "metadata": {
        "id": "N6HkI04F0efd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls "
      ],
      "metadata": {
        "id": "uSfh1QJq0nLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model = torch.load('my_model')"
      ],
      "metadata": {
        "id": "I8coSW2V0t3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_tensor = saved_model(x_test_tensor)"
      ],
      "metadata": {
        "id": "lDc7dyjb0us7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = y_pred_tensor.detach().numpy()\n",
        "y_pred"
      ],
      "metadata": {
        "id": "Xb5RYPkH000z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/MindaugasBernatavicius/DeepLearningCourse/raw/master/06_Regression_with_Neural_Networks_and_Tabular_Data/28865_36778_bundle_archive.zip \n",
        "!unzip -n *archive.zip\n",
        "# !rm -rf bike-sharing-dataset/\n",
        "!rm -f *.txt *.csv\n",
        "!rm -f my_model"
      ],
      "metadata": {
        "id": "HGN81NlF05Wl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('./bike-sharing-dataset/hour.csv', index_col=0)\n",
        "\n",
        "columns = ['registered', 'holiday', 'weekday', 'weathersit', 'temp', 'atemp', 'season']\n",
        "\n",
        "features = data[columns]\n",
        "target = data[['cnt']]\n",
        "\n",
        "X_train, x_test, Y_train, y_test = train_test_split(features, target, test_size=0.2)\n",
        "\n",
        "# clf = DecisionTreeRegressor(max_depth=4)\n",
        "clf = DecisionTreeRegressor()\n",
        "clf.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "OgJ23zrV1COc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf.feature_importances_\n",
        "# columns = ['registered', 'holiday', 'weekday', 'weathersit', 'temp', 'atemp', 'season']"
      ],
      "metadata": {
        "id": "uuv0AhzH1EeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pytorch model in one place"
      ],
      "metadata": {
        "id": "xoOEcja68r-K"
      }
    }
  ]
}