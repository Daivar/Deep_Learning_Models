{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_intro.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMF2dy0gyGqYmswG70Xcqgu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Daivar/Deep_Learning_Models/blob/main/NLP_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "w66-Wg5F5S3E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eec5404e-4037-4cd4-e5a8-555dd3d939d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.2.5\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import nltk\n",
        "print(nltk.__version__)\n",
        "\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import gutenberg\n",
        "gutenberg.fileids() #shows the file id's of file in this corpora"
      ],
      "metadata": {
        "id": "27jnmIYa5bEv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b477bc0-f73d-420c-eedd-188c622b14b9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['austen-emma.txt',\n",
              " 'austen-persuasion.txt',\n",
              " 'austen-sense.txt',\n",
              " 'bible-kjv.txt',\n",
              " 'blake-poems.txt',\n",
              " 'bryant-stories.txt',\n",
              " 'burgess-busterbrown.txt',\n",
              " 'carroll-alice.txt',\n",
              " 'chesterton-ball.txt',\n",
              " 'chesterton-brown.txt',\n",
              " 'chesterton-thursday.txt',\n",
              " 'edgeworth-parents.txt',\n",
              " 'melville-moby_dick.txt',\n",
              " 'milton-paradise.txt',\n",
              " 'shakespeare-caesar.txt',\n",
              " 'shakespeare-hamlet.txt',\n",
              " 'shakespeare-macbeth.txt',\n",
              " 'whitman-leaves.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emma_sents = gutenberg.sents('austen-emma.txt')\n",
        "\n",
        "# .words will give all the words.\n",
        "# .raw will give the whole book with ‘\\n’ for new line\n",
        "# .sents will give all the sentences in list.\n",
        "\n",
        "print(list(emma_sents))\n",
        "print(list(emma_sents[1500]))"
      ],
      "metadata": {
        "id": "S8EOnjtv5opE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ! ls -alht /root/nltk_data/corpora/gutenberg\n",
        "! ls -alht /root/nltk_data/corpora/"
      ],
      "metadata": {
        "id": "qTfsXeoR5u_k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bccd31b-f52f-47d1-e419-f4227851d5d8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4.1M\n",
            "drwxr-xr-x 4 root root 4.0K Jan 17 16:37 ..\n",
            "drwxr-xr-x 2 root root 4.0K Jan 17 16:37 gutenberg\n",
            "drwxr-xr-x 3 root root 4.0K Jan 17 16:37 .\n",
            "-rw-r--r-- 1 root root 4.1M Jan 17 16:37 gutenberg.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sample = gutenberg.raw('bible-kjv.txt')\n",
        "toks = sent_tokenize(sample)\n",
        "\n",
        "toks[10:12]"
      ],
      "metadata": {
        "id": "Fwy5PSLH5xpd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ebafabd-2e2d-4974-c87c-5749c4a4695c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['And the evening and the\\nmorning were the second day.',\n",
              " '1:9 And God said, Let the waters under the heaven be gathered together\\nunto one place, and let the dry land appear: and it was so.']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sample)"
      ],
      "metadata": {
        "id": "wWhujbct6CR7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b044f490-21ca-4cd7-c4f6-a9a6376eaf2a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pprint\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "URL = 'https://www.monster.com/jobs/search/?q=Software-Developer&where=Australia'\n",
        "page = requests.get(URL)\n",
        "page.content"
      ],
      "metadata": {
        "id": "DegMg_18594M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dir(page)\n",
        "# page.content.decode(\"utf-8\")\n",
        "\n",
        "# pp = pprint.PrettyPrinter(indent=4)\n",
        "# pp.pprint(page.content)\n",
        "\n",
        "soup = BeautifulSoup(page.content, 'html.parser')\n",
        "soup"
      ],
      "metadata": {
        "id": "RMEKs8hD6Ps0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip3 install SpeechRecognition"
      ],
      "metadata": {
        "id": "eI3B3aC16cb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc9fcaf1-5ad5-4fe0-ac12-31ca79cb13f8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.8.1-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8 MB 54.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: SpeechRecognition\n",
            "Successfully installed SpeechRecognition-3.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/realpython/python-speech-recognition/blob/master/audio_files/harvard.wav?raw=true -O harvard.wav"
      ],
      "metadata": {
        "id": "ppXwUVSW6nSV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c98a38e7-aff3-4beb-8e39-9287fd74ee70"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-17 16:38:08--  https://github.com/realpython/python-speech-recognition/blob/master/audio_files/harvard.wav?raw=true\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/realpython/python-speech-recognition/raw/master/audio_files/harvard.wav [following]\n",
            "--2022-01-17 16:38:08--  https://github.com/realpython/python-speech-recognition/raw/master/audio_files/harvard.wav\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/realpython/python-speech-recognition/master/audio_files/harvard.wav [following]\n",
            "--2022-01-17 16:38:09--  https://raw.githubusercontent.com/realpython/python-speech-recognition/master/audio_files/harvard.wav\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3249924 (3.1M) [audio/wav]\n",
            "Saving to: ‘harvard.wav’\n",
            "\n",
            "harvard.wav         100%[===================>]   3.10M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-01-17 16:38:09 (48.2 MB/s) - ‘harvard.wav’ saved [3249924/3249924]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import speech_recognition as sr\n",
        "\n",
        "r = sr.Recognizer()\n",
        "harvard = sr.AudioFile('harvard.wav')\n",
        "with harvard as source:\n",
        "  audio = r.record(source)"
      ],
      "metadata": {
        "id": "kQAfXEXT6rT1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r.recognize_google(audio)"
      ],
      "metadata": {
        "id": "Krcdpcxf6ulY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "9f4c5aad-b2b3-47d5-f921-b9a0597e124c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'the stale smell of old beer lingers it takes heat to bring out the odor a cold dip restores health and zest a salt pickle taste fine with ham tacos al Pastore are my favorite acceptable food is be hot cross bun'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download(\"popular\")\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "\n",
        "import os\n",
        "import matplotlib as mpl\n",
        "if os.environ.get('DISPLAY','') == '':\n",
        "    print('no display found. Using non-interactive Agg backend')\n",
        "    mpl.use('Agg')\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "RJ2ZQBqh_MKf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57f8dfd2-74f1-456f-bc71-30de68e72329"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw-1.4.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2021.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet31.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n",
            "no display found. Using non-interactive Agg backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentence tokenezation \n",
        "\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize"
      ],
      "metadata": {
        "id": "ca4xzf9-_dpV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3599d85-05e1-4483-bcfb-c1ed92fb5204"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# don't need to worry about what symbol is at the end the sentece\n",
        "text = \"Mary had a little lamb. Her fleece was white as snow. A?\"\n",
        "sentences = sent_tokenize(text)\n",
        "print(sentences)\n",
        "print(sentences[0])\n"
      ],
      "metadata": {
        "id": "Ej7SCPqA_iH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e01d5f26-be95-4afb-fc0e-d766aeb1eb58"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Mary had a little lamb.', 'Her fleece was white as snow.', 'A?']\n",
            "Mary had a little lamb.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Word tokenization\n",
        "\n",
        "words=[word_tokenize(sentence) for sentence in sentences]\n",
        "print(words)\n",
        "\n",
        "# or we can tokenize the entire sentence\n",
        "text = \"Mary had a little lamb. Her fleece was white as snow\"\n",
        "words = word_tokenize(text)\n",
        "print(words)"
      ],
      "metadata": {
        "id": "oxA5WbCc_sN1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0054a70a-f671-4e84-aee4-d86e207fab06"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Mary', 'had', 'a', 'little', 'lamb', '.'], ['Her', 'fleece', 'was', 'white', 'as', 'snow', '.'], ['A', '?']]\n",
            "['Mary', 'had', 'a', 'little', 'lamb', '.', 'Her', 'fleece', 'was', 'white', 'as', 'snow']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lowercase(intext):\n",
        "    return intext.lower()    \n",
        "\n",
        "#Alternatively:\n",
        "#orig = data.raw(r'file.text') # read raw text form orignal file\n",
        "#sent = data.sents(r'file.txt') # brake parah into sentance\n",
        "#bwords = data.words(r'file.text')# break parah into words\n",
        "\n",
        "intext = input('Your-Text:')\n",
        "clean_text = lowercase(intext)\n",
        "print('\\nlowercased:', lowercase(clean_text))"
      ],
      "metadata": {
        "id": "vfML_WuZJDID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56705a63-fbb3-488f-e0ba-0e6d24d2cc24"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your-Text:Snow Is Falling Down So Fast \n",
            "\n",
            "lowercased: snow is falling down so fast \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "output = string.punctuation\n",
        "print('list of punctuations:', output)\n",
        "\n",
        "def punctuation_cleaning(intext):\n",
        "    return intext.translate(str.maketrans('', '', output))\n",
        "\n",
        "print('\\nNo-punctuation:', punctuation_cleaning(clean_text))"
      ],
      "metadata": {
        "id": "KW-SxtZ0JeoA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7f25626-d044-4038-a46b-a2db110e45f6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "list of punctuations: !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "\n",
            "No-punctuation: snow is falling down so fast \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def url_remove(text):\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+|blog\\.\\S+')\n",
        "    return url_pattern.sub(r'',  text)\n",
        "\n",
        "def url_remove_w_replacement(text):\n",
        "    return re.sub(r'https?://\\S+|www\\.\\S+|blog\\.\\S+', '<domain>', text)\n",
        "\n",
        "def html_remove(text):\n",
        "    html_pattern = re.compile('<.*?>')\n",
        "    return html_pattern.sub(r'', text)\n",
        "\n",
        "text1 = input('Your-Text:')\n",
        "print('\\nNo-url-links:', url_remove(text1))\n",
        "print('\\nNo-url-links:', url_remove_w_replacement(text1))\n",
        "text2 = input('Your Text:')\n",
        "print('\\nNo-html-codes:', html_remove(text2))\n",
        "\n",
        "# Test strings:\n",
        "# Get more informtion at https://www.delfi.lt\n",
        "# The title is <title>Hello world</title> and it's amazing!"
      ],
      "metadata": {
        "id": "AbL0ASCSJj-9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7af3293b-9721-4d04-a360-3257503c0dd1"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your-Text:Please write me an e-mail which you will find it on www.imone.lt\n",
            "\n",
            "No-url-links: Please write me an e-mail which you will find it on \n",
            "\n",
            "No-url-links: Please write me an e-mail which you will find it on <domain>\n",
            "Your Text:Get more informtion at https://www.delfi.lt\n",
            "\n",
            "No-html-codes: Get more informtion at https://www.delfi.lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stemming\n",
        "\n",
        "text2 = \"Mary closed on closing night when she was in the mood to close.\"\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "st = LancasterStemmer()\n",
        "stemmedWords=[st.stem(word) for word in word_tokenize(text2)]\n",
        "print(stemmedWords)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mrb3Ahl5hWG",
        "outputId": "164891e5-8496-43ae-a854-3d5e803610b3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['mary', 'clos', 'on', 'clos', 'night', 'when', 'she', 'was', 'in', 'the', 'mood', 'to', 'clos', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lematization\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "print(lemmatizer.lemmatize('cats'))\n",
        "print(lemmatizer.lemmatize('better', 'a'))\n",
        "print(lemmatizer.lemmatize('worse'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZ6zc0eX6bQy",
        "outputId": "2cfaa8b6-30c7-42dc-c25a-33f1fcdf33bd"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "cat\n",
            "good\n",
            "worse\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "sentence = \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun. This makes him worse at the skill of survival\"\n",
        "punctuations=\"?:!.,;\"\n",
        "sentence_words = nltk.word_tokenize(sentence)\n",
        "for word in sentence_words:\n",
        "    if word in punctuations:\n",
        "        sentence_words.remove(word)\n",
        "\n",
        "sentence_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fERj_NhP6n2t",
        "outputId": "a61a8644-fe59-44f2-f87a-3c00ed41a034"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['He',\n",
              " 'was',\n",
              " 'running',\n",
              " 'and',\n",
              " 'eating',\n",
              " 'at',\n",
              " 'same',\n",
              " 'time',\n",
              " 'He',\n",
              " 'has',\n",
              " 'bad',\n",
              " 'habit',\n",
              " 'of',\n",
              " 'swimming',\n",
              " 'after',\n",
              " 'playing',\n",
              " 'long',\n",
              " 'hours',\n",
              " 'in',\n",
              " 'the',\n",
              " 'Sun',\n",
              " 'This',\n",
              " 'makes',\n",
              " 'him',\n",
              " 'worse',\n",
              " 'at',\n",
              " 'the',\n",
              " 'skill',\n",
              " 'of',\n",
              " 'survival']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"{0:20}{1:20}\".format(\"Word\",\"Lemma\"))\n",
        "for word in sentence_words:\n",
        "    print(\"{0:20}{1:20}\".format(word, wordnet_lemmatizer.lemmatize(word, 'a')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3ldOxj76tER",
        "outputId": "4a3f6bfd-dbef-4d3e-909b-46640183d7c0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                Lemma               \n",
            "He                  He                  \n",
            "was                 was                 \n",
            "running             running             \n",
            "and                 and                 \n",
            "eating              eating              \n",
            "at                  at                  \n",
            "same                same                \n",
            "time                time                \n",
            "He                  He                  \n",
            "has                 has                 \n",
            "bad                 bad                 \n",
            "habit               habit               \n",
            "of                  of                  \n",
            "swimming            swimming            \n",
            "after               after               \n",
            "playing             playing             \n",
            "long                long                \n",
            "hours               hours               \n",
            "in                  in                  \n",
            "the                 the                 \n",
            "Sun                 Sun                 \n",
            "This                This                \n",
            "makes               makes               \n",
            "him                 him                 \n",
            "worse               bad                 \n",
            "at                  at                  \n",
            "the                 the                 \n",
            "skill               skill               \n",
            "of                  of                  \n",
            "survival            survival            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in sentence_words:\n",
        "    print (\"{0:20}{1:20}\".format(word,wordnet_lemmatizer.lemmatize(word, pos=\"v\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyfN24QT7Des",
        "outputId": "6b0f8bd0-32fd-4966-dec4-66715aa60d19"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "He                  He                  \n",
            "was                 be                  \n",
            "running             run                 \n",
            "and                 and                 \n",
            "eating              eat                 \n",
            "at                  at                  \n",
            "same                same                \n",
            "time                time                \n",
            "He                  He                  \n",
            "has                 have                \n",
            "bad                 bad                 \n",
            "habit               habit               \n",
            "of                  of                  \n",
            "swimming            swim                \n",
            "after               after               \n",
            "playing             play                \n",
            "long                long                \n",
            "hours               hours               \n",
            "in                  in                  \n",
            "the                 the                 \n",
            "Sun                 Sun                 \n",
            "This                This                \n",
            "makes               make                \n",
            "him                 him                 \n",
            "worse               worse               \n",
            "at                  at                  \n",
            "the                 the                 \n",
            "skill               skill               \n",
            "of                  of                  \n",
            "survival            survival            \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tagging parts of speach\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop = set(stopwords.words('english'))\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "tagged = nltk.pos_tag(wordsWOStopwords)\n",
        "tagged"
      ],
      "metadata": {
        "id": "4Yd_LBYh7FHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tagged = nltk.pos_tag(words)\n",
        "tagged"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c2HYbP_9PIq",
        "outputId": "862d5457-ac5f-461f-e66b-62b17dec9874"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Mary', 'NNP'),\n",
              " ('had', 'VBD'),\n",
              " ('a', 'DT'),\n",
              " ('little', 'JJ'),\n",
              " ('lamb', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Her', 'PRP$'),\n",
              " ('fleece', 'NN'),\n",
              " ('was', 'VBD'),\n",
              " ('white', 'JJ'),\n",
              " ('as', 'IN'),\n",
              " ('snow', 'NN')]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet as wn\n",
        "\n",
        "for ss in wn.synsets('bass'):\n",
        "    print(ss, ss.definition())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoiaFt179S-V",
        "outputId": "72a612a5-5964-45df-fea7-26d99cd3d556"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "Synset('bass.n.01') the lowest part of the musical range\n",
            "Synset('bass.n.02') the lowest part in polyphonic music\n",
            "Synset('bass.n.03') an adult male singer with the lowest voice\n",
            "Synset('sea_bass.n.01') the lean flesh of a saltwater fish of the family Serranidae\n",
            "Synset('freshwater_bass.n.01') any of various North American freshwater fish with lean flesh (especially of the genus Micropterus)\n",
            "Synset('bass.n.06') the lowest adult male singing voice\n",
            "Synset('bass.n.07') the member with the lowest range of a family of musical instruments\n",
            "Synset('bass.n.08') nontechnical name for any of numerous edible marine and freshwater spiny-finned fishes\n",
            "Synset('bass.s.01') having or denoting a low vocal or instrumental range\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.wsd import lesk\n",
        "\n",
        "sense1 = lesk(word_tokenize(\"Sing in a lower tone, along with the bass\"),'bass')\n",
        "print(sense1, sense1.definition())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FtIU_UO9dDs",
        "outputId": "cc28b5aa-f302-401f-89e2-cc5412c22cf6"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('bass.n.07') the member with the lowest range of a family of musical instruments\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sense2 = lesk(word_tokenize(\"This sea bass was really hard to catch\"), 'bass')\n",
        "print(sense2, sense2.definition())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvy_v4Oa9kSG",
        "outputId": "1779d94f-c858-46e7-b6a3-bd59b70c222f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synset('sea_bass.n.01') the lean flesh of a saltwater fish of the family Serranidae\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display parse tree\n",
        "\n",
        "from nltk import chunk\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "\n",
        "tree = chunk.ne_chunk(tagged)\n",
        "tree"
      ],
      "metadata": {
        "id": "9x9ZR_VM9pVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tree import Tree\n",
        "from nltk.draw.tree import TreeView\n",
        "t = Tree.fromstring('(S (NP this tree) (VP (V is) (AdjP pretty)))')\n",
        "TreeView(t)._cframe.print_to_file('output.ps')"
      ],
      "metadata": {
        "id": "GEGaMTp596eH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nltk\n",
        "from IPython.display import Image\n",
        "\n",
        "chunkGram = r\"\"\"Chunk: {<RB.?>*<VB.?>*<NNP>+<NN>?}\"\"\"\n",
        "chunkParser = nltk.RegexpParser(chunkGram)\n",
        "\n",
        "tagged = [('Tonight', 'NN'), ('we', 'PRP'), ('are', 'VBP'), ('comforted', 'VBN'), ('by', 'IN'), ('the', 'DT'), ('hope', 'NN'), ('of', 'IN'), ('a', 'DT'), ('glad', 'JJ'), ('reunion', 'NN'), ('with', 'IN'), ('the', 'DT'), ('husband', 'NN'), ('who', 'WP'), ('was', 'VBD'), ('taken', 'VBN'), ('so', 'RB'), ('long', 'RB'), ('ago', 'RB'), (',', ','), ('and', 'CC'), ('we', 'PRP'), ('are', 'VBP'), ('grateful', 'JJ'), ('for', 'IN'), ('the', 'DT'), ('good', 'JJ'), ('life', 'NN'), ('of', 'IN'), ('Coretta', 'NNP'), ('Scott', 'NNP'), ('King', 'NNP'), ('.', '.')]\n",
        "chunked = chunkParser.parse(tagged)\n",
        "nltk.draw.tree.TreeView(chunked)._cframe.print_to_file('output.ps')\n",
        "os.system('convert output.ps output.png')\n",
        "\n",
        "Image(filename='output.png') "
      ],
      "metadata": {
        "id": "mTWLvo0G9-ld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Auto summarization\n",
        "\n",
        "import urllib3\n",
        "from bs4 import BeautifulSoup\n",
        "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
      ],
      "metadata": {
        "id": "rLQNN53q-IXs"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "articleURL = \"https://www.washingtonpost.com/news/the-switch/wp/2016/10/18/the-pentagons-massive-new-telescope-is-designed-to-track-space-junk-and-watch-out-for-killer-asteroids/\""
      ],
      "metadata": {
        "id": "VY1Qs6bf-TZj"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# it is necessary to spoof the header, see: https://stackoverflow.com/questions/65308838/urllib3-does-not-open-the-same-article-as-urllib2-was-able-to-open-due-to-privat\n",
        "headers = {'user-agent': 'Mozilla/5.0 (Windows NT x.y; Win64; x64; rv:10.0) Gecko/20100101 Firefox/10.0'}\n",
        "\n",
        "http = urllib3.PoolManager()\n",
        "response = http.request('GET', articleURL, headers=headers)\n",
        "soup = BeautifulSoup(response.data.decode('utf-8', 'ignore'), 'lxml')\n",
        "soup"
      ],
      "metadata": {
        "id": "YEXL3n5i-Uxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup.find('article')"
      ],
      "metadata": {
        "id": "1h5VmhPj-dfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soup.find('article').text  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "SCnGM0C8-h6w",
        "outputId": "23b6c54f-61ce-41f7-b331-2c55c1e9575e"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"The Space Surveillance Telescope offers improvements in determining the orbits of newly discovered objects and provides rapid observations of space events. (DARPAtv)By  Christian DavenportOctober 18, 2016By  Christian DavenportOctober 18, 2016There are a lot of rocks flying around through space. Lots of debris, too. Old satellites, spent rocket boosters, even for a short while a spatula that got loose during a space shuttle mission in 2006. All of it swirling around in orbit, creating a bit of a traffic jam.WpGet the full experience.Choose your planArrowRightFor years, the Pentagon has been worried about the collisions that might be caused by an\\xa0estimated 500,000 pieces of debris, taking out enormously valuable satellites and, in turn, creating even more debris. On Tuesday, the Defense Department\\xa0took another significant step toward monitoring all of the cosmic junk swirling around in space, by delivering\\xa0a gigantic new telescope capable of seeing small objects from very far away.Developed by the Defense Advanced Research Project Agency, the Space Surveillance Telescope was formally transferred to the Air Force during a ceremony at White Sands Missile Base in New Mexico Tuesday.AdvertisementStory continues below advertisementThe telescope is designed to monitor objects as small as softballs, in Geosynchonous orbit (GEO)—some of the most important real estate in space. At about 22,000 miles away, its orbit mirrors that of the Earth, so that satellites parked there remain in a fixed point over the globe. That allows satellite television or communications providers to serve particular areas—say, North America or Asia—uninterrupted.But not only is the orbit far away—it’s incredibly vast. “A volume of tens of thousands of oceans,” said Lindsay Millard, DARPA’s program manager in a podcast posted on the agency’s website. But the telescope's ability to see “something very far away over a very wide area is really what it’s best at.”DARPA says the advanced technology in the massive, 90-ton telescope would\\xa0allow officials to go from “seeing only a few large objects at a time through the equivalent of a drinking straw to a windshield view with 10,000 objects at a time.”\\xa0It is also being used by NASA to monitor asteroids and other near-Earth objects that could collide with the planet, officials said.AdvertisementStory continues below advertisementOver the next two years, the telescope is going to be moved and reconstructed in Australia, a vantage point that would allow it to survey an under served area of space.The telescope is “a big improvement over the legacy ground-based optical telescopes that are used by the U.S. Air Force, because it can search large areas of sky and also track very faint (small) objects in and around GEO,” Brian Weeden, a Technical Advisor at the Secure World Foundation, wrote in an email. “That's a critical capability for the U.S. military, as they have a lot of very important satellites in GEO, and are increasingly worried about threats to those satellites.”The telescope would\\xa0join another new space debris tracking technology known as the Space Fence, which is now being built by Bethesda-based Lockheed Martin. The radar system is going to be located on Kwajalein Atoll in the Marshall Islands and would use radar to help the Air Force track 10 times amount of debris than it currently monitors.AdvertisementStory continues below advertisementWith many valuable assets in space—satellites used for intelligence, communications and guiding weapons—the Pentagon has become increasingly concerned with what it calls “space situational awareness.” Instead of being a benign environment, the Pentagon likes to say that space has become “contested, congested and competitive.” In orbit, debris moves very fast, as much as 17,500 m.p.h., so that even a fleck of paint could cause damage.In 2007, the Chinese fired a missile that blew up a dead satellite and littered space with thousands of pieces of debris. And the Air Force has been working to make its satellites more resilient. It has plans to send swarms of small satellites into orbit that are more difficult to target.“Every military operation that takes place in the world today is critically dependent on space in one way or another,” Air Force Gen. John Hyten said in an interview earlier this year when he was the commander of the Air Force Space Command. “Whether our own people in the United States are fully cognizant of the dependence on space or not, the rest of the world has been watching us very closely.”GiftOutlineGift ArticleLoading...\""
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = ' '.join(map(lambda p: p.text, soup.find_all('article')))\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "uTUeIpJ1EsY7",
        "outputId": "816782fc-1b0f-46c4-cc18-09d91fb4923b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"The Space Surveillance Telescope offers improvements in determining the orbits of newly discovered objects and provides rapid observations of space events. (DARPAtv)By  Christian DavenportOctober 18, 2016By  Christian DavenportOctober 18, 2016There are a lot of rocks flying around through space. Lots of debris, too. Old satellites, spent rocket boosters, even for a short while a spatula that got loose during a space shuttle mission in 2006. All of it swirling around in orbit, creating a bit of a traffic jam.WpGet the full experience.Choose your planArrowRightFor years, the Pentagon has been worried about the collisions that might be caused by an\\xa0estimated 500,000 pieces of debris, taking out enormously valuable satellites and, in turn, creating even more debris. On Tuesday, the Defense Department\\xa0took another significant step toward monitoring all of the cosmic junk swirling around in space, by delivering\\xa0a gigantic new telescope capable of seeing small objects from very far away.Developed by the Defense Advanced Research Project Agency, the Space Surveillance Telescope was formally transferred to the Air Force during a ceremony at White Sands Missile Base in New Mexico Tuesday.AdvertisementStory continues below advertisementThe telescope is designed to monitor objects as small as softballs, in Geosynchonous orbit (GEO)—some of the most important real estate in space. At about 22,000 miles away, its orbit mirrors that of the Earth, so that satellites parked there remain in a fixed point over the globe. That allows satellite television or communications providers to serve particular areas—say, North America or Asia—uninterrupted.But not only is the orbit far away—it’s incredibly vast. “A volume of tens of thousands of oceans,” said Lindsay Millard, DARPA’s program manager in a podcast posted on the agency’s website. But the telescope's ability to see “something very far away over a very wide area is really what it’s best at.”DARPA says the advanced technology in the massive, 90-ton telescope would\\xa0allow officials to go from “seeing only a few large objects at a time through the equivalent of a drinking straw to a windshield view with 10,000 objects at a time.”\\xa0It is also being used by NASA to monitor asteroids and other near-Earth objects that could collide with the planet, officials said.AdvertisementStory continues below advertisementOver the next two years, the telescope is going to be moved and reconstructed in Australia, a vantage point that would allow it to survey an under served area of space.The telescope is “a big improvement over the legacy ground-based optical telescopes that are used by the U.S. Air Force, because it can search large areas of sky and also track very faint (small) objects in and around GEO,” Brian Weeden, a Technical Advisor at the Secure World Foundation, wrote in an email. “That's a critical capability for the U.S. military, as they have a lot of very important satellites in GEO, and are increasingly worried about threats to those satellites.”The telescope would\\xa0join another new space debris tracking technology known as the Space Fence, which is now being built by Bethesda-based Lockheed Martin. The radar system is going to be located on Kwajalein Atoll in the Marshall Islands and would use radar to help the Air Force track 10 times amount of debris than it currently monitors.AdvertisementStory continues below advertisementWith many valuable assets in space—satellites used for intelligence, communications and guiding weapons—the Pentagon has become increasingly concerned with what it calls “space situational awareness.” Instead of being a benign environment, the Pentagon likes to say that space has become “contested, congested and competitive.” In orbit, debris moves very fast, as much as 17,500 m.p.h., so that even a fleck of paint could cause damage.In 2007, the Chinese fired a missile that blew up a dead satellite and littered space with thousands of pieces of debris. And the Air Force has been working to make its satellites more resilient. It has plans to send swarms of small satellites into orbit that are more difficult to target.“Every military operation that takes place in the world today is critically dependent on space in one way or another,” Air Force Gen. John Hyten said in an interview earlier this year when he was the commander of the Air Force Space Command. “Whether our own people in the United States are fully cognizant of the dependence on space or not, the rest of the world has been watching us very closely.”GiftOutlineGift ArticleLoading...\""
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = text.replace(\"?\",\" \")\n",
        "text = text.replace('\\xa0', ' ')\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "lNjBN5pEE1cF",
        "outputId": "2dce91f3-97a5-4417-f8d8-e32d69542768"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"The Space Surveillance Telescope offers improvements in determining the orbits of newly discovered objects and provides rapid observations of space events. (DARPAtv)By  Christian DavenportOctober 18, 2016By  Christian DavenportOctober 18, 2016There are a lot of rocks flying around through space. Lots of debris, too. Old satellites, spent rocket boosters, even for a short while a spatula that got loose during a space shuttle mission in 2006. All of it swirling around in orbit, creating a bit of a traffic jam.WpGet the full experience.Choose your planArrowRightFor years, the Pentagon has been worried about the collisions that might be caused by an estimated 500,000 pieces of debris, taking out enormously valuable satellites and, in turn, creating even more debris. On Tuesday, the Defense Department took another significant step toward monitoring all of the cosmic junk swirling around in space, by delivering a gigantic new telescope capable of seeing small objects from very far away.Developed by the Defense Advanced Research Project Agency, the Space Surveillance Telescope was formally transferred to the Air Force during a ceremony at White Sands Missile Base in New Mexico Tuesday.AdvertisementStory continues below advertisementThe telescope is designed to monitor objects as small as softballs, in Geosynchonous orbit (GEO)—some of the most important real estate in space. At about 22,000 miles away, its orbit mirrors that of the Earth, so that satellites parked there remain in a fixed point over the globe. That allows satellite television or communications providers to serve particular areas—say, North America or Asia—uninterrupted.But not only is the orbit far away—it’s incredibly vast. “A volume of tens of thousands of oceans,” said Lindsay Millard, DARPA’s program manager in a podcast posted on the agency’s website. But the telescope's ability to see “something very far away over a very wide area is really what it’s best at.”DARPA says the advanced technology in the massive, 90-ton telescope would allow officials to go from “seeing only a few large objects at a time through the equivalent of a drinking straw to a windshield view with 10,000 objects at a time.” It is also being used by NASA to monitor asteroids and other near-Earth objects that could collide with the planet, officials said.AdvertisementStory continues below advertisementOver the next two years, the telescope is going to be moved and reconstructed in Australia, a vantage point that would allow it to survey an under served area of space.The telescope is “a big improvement over the legacy ground-based optical telescopes that are used by the U.S. Air Force, because it can search large areas of sky and also track very faint (small) objects in and around GEO,” Brian Weeden, a Technical Advisor at the Secure World Foundation, wrote in an email. “That's a critical capability for the U.S. military, as they have a lot of very important satellites in GEO, and are increasingly worried about threats to those satellites.”The telescope would join another new space debris tracking technology known as the Space Fence, which is now being built by Bethesda-based Lockheed Martin. The radar system is going to be located on Kwajalein Atoll in the Marshall Islands and would use radar to help the Air Force track 10 times amount of debris than it currently monitors.AdvertisementStory continues below advertisementWith many valuable assets in space—satellites used for intelligence, communications and guiding weapons—the Pentagon has become increasingly concerned with what it calls “space situational awareness.” Instead of being a benign environment, the Pentagon likes to say that space has become “contested, congested and competitive.” In orbit, debris moves very fast, as much as 17,500 m.p.h., so that even a fleck of paint could cause damage.In 2007, the Chinese fired a missile that blew up a dead satellite and littered space with thousands of pieces of debris. And the Air Force has been working to make its satellites more resilient. It has plans to send swarms of small satellites into orbit that are more difficult to target.“Every military operation that takes place in the world today is critically dependent on space in one way or another,” Air Force Gen. John Hyten said in an interview earlier this year when he was the commander of the Air Force Space Command. “Whether our own people in the United States are fully cognizant of the dependence on space or not, the rest of the world has been watching us very closely.”GiftOutlineGift ArticleLoading...\""
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getTextWaPo(url):\n",
        "    page = urllib2.urlopen(url).read().decode('utf8')\n",
        "    soup = BeautifulSoup(page,\"lxml\")\n",
        "    text = ' '.join(map(lambda p: p.text, soup.find_all('article')))\n",
        "    return text.encode('ascii', errors='replace').replace(\"?\",\" \")\n",
        "\n",
        "text = getTextWaPo(articleURL)"
      ],
      "metadata": {
        "id": "61L3mtKUFC5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZimwAgRkG-1T",
        "outputId": "efeafde6-5d27-4a2d-d354-9cfaa5a42e3b"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sents = sent_tokenize(text)\n",
        "print(sents)\n",
        "print(len(sents))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff9MFuiqHAaK",
        "outputId": "b5e9bef0-db81-4d46-b228-b0e882b82a26"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The Space Surveillance Telescope offers improvements in determining the orbits of newly discovered objects and provides rapid observations of space events.', '(DARPAtv)By  Christian DavenportOctober 18, 2016By  Christian DavenportOctober 18, 2016There are a lot of rocks flying around through space.', 'Lots of debris, too.', 'Old satellites, spent rocket boosters, even for a short while a spatula that got loose during a space shuttle mission in 2006.', 'All of it swirling around in orbit, creating a bit of a traffic jam.WpGet the full experience.Choose your planArrowRightFor years, the Pentagon has been worried about the collisions that might be caused by an estimated 500,000 pieces of debris, taking out enormously valuable satellites and, in turn, creating even more debris.', 'On Tuesday, the Defense Department took another significant step toward monitoring all of the cosmic junk swirling around in space, by delivering a gigantic new telescope capable of seeing small objects from very far away.Developed by the Defense Advanced Research Project Agency, the Space Surveillance Telescope was formally transferred to the Air Force during a ceremony at White Sands Missile Base in New Mexico Tuesday.AdvertisementStory continues below advertisementThe telescope is designed to monitor objects as small as softballs, in Geosynchonous orbit (GEO)—some of the most important real estate in space.', 'At about 22,000 miles away, its orbit mirrors that of the Earth, so that satellites parked there remain in a fixed point over the globe.', 'That allows satellite television or communications providers to serve particular areas—say, North America or Asia—uninterrupted.But not only is the orbit far away—it’s incredibly vast.', '“A volume of tens of thousands of oceans,” said Lindsay Millard, DARPA’s program manager in a podcast posted on the agency’s website.', \"But the telescope's ability to see “something very far away over a very wide area is really what it’s best at.”DARPA says the advanced technology in the massive, 90-ton telescope would allow officials to go from “seeing only a few large objects at a time through the equivalent of a drinking straw to a windshield view with 10,000 objects at a time.” It is also being used by NASA to monitor asteroids and other near-Earth objects that could collide with the planet, officials said.AdvertisementStory continues below advertisementOver the next two years, the telescope is going to be moved and reconstructed in Australia, a vantage point that would allow it to survey an under served area of space.The telescope is “a big improvement over the legacy ground-based optical telescopes that are used by the U.S. Air Force, because it can search large areas of sky and also track very faint (small) objects in and around GEO,” Brian Weeden, a Technical Advisor at the Secure World Foundation, wrote in an email.\", \"“That's a critical capability for the U.S. military, as they have a lot of very important satellites in GEO, and are increasingly worried about threats to those satellites.”The telescope would join another new space debris tracking technology known as the Space Fence, which is now being built by Bethesda-based Lockheed Martin.\", 'The radar system is going to be located on Kwajalein Atoll in the Marshall Islands and would use radar to help the Air Force track 10 times amount of debris than it currently monitors.AdvertisementStory continues below advertisementWith many valuable assets in space—satellites used for intelligence, communications and guiding weapons—the Pentagon has become increasingly concerned with what it calls “space situational awareness.” Instead of being a benign environment, the Pentagon likes to say that space has become “contested, congested and competitive.” In orbit, debris moves very fast, as much as 17,500 m.p.h., so that even a fleck of paint could cause damage.In 2007, the Chinese fired a missile that blew up a dead satellite and littered space with thousands of pieces of debris.', 'And the Air Force has been working to make its satellites more resilient.', 'It has plans to send swarms of small satellites into orbit that are more difficult to target.“Every military operation that takes place in the world today is critically dependent on space in one way or another,” Air Force Gen. John Hyten said in an interview earlier this year when he was the commander of the Air Force Space Command.', '“Whether our own people in the United States are fully cognizant of the dependence on space or not, the rest of the world has been watching us very closely.”GiftOutlineGift ArticleLoading...']\n",
            "15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_sent = word_tokenize(text.lower())\n",
        "word_sent"
      ],
      "metadata": {
        "id": "DpATw26XHGSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "_stopwords = set(stopwords.words('english') + list(punctuation))\n",
        "_stopwords"
      ],
      "metadata": {
        "id": "_p0GC2p9HKIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_sent=[word for word in word_sent if word not in _stopwords]\n",
        "word_sent"
      ],
      "metadata": {
        "id": "58VznVXiHPCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from heapq import nlargest\n",
        "nlargest(10, freq, key=freq.get)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXInZdGPHX3T",
        "outputId": "6bd4fe2a-5bbc-4d10-dbb2-8e158659690d"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['space',\n",
              " 'telescope',\n",
              " '“',\n",
              " '”',\n",
              " 'objects',\n",
              " 'debris',\n",
              " 'satellites',\n",
              " 'orbit',\n",
              " 'air',\n",
              " 'force']"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "ranking = defaultdict(int)\n",
        "\n",
        "for i, sent in enumerate(sents):\n",
        "    for w in word_tokenize(sent.lower()):\n",
        "        if w in freq:\n",
        "            ranking[i] += freq[w]\n",
        " \n",
        "ranking"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wmjUfShHc2t",
        "outputId": "559ef35b-7102-4e07-fa6d-0e20c5b76b8d"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int,\n",
              "            {0: 58,\n",
              "             1: 38,\n",
              "             2: 8,\n",
              "             3: 34,\n",
              "             4: 64,\n",
              "             5: 184,\n",
              "             6: 24,\n",
              "             7: 29,\n",
              "             8: 44,\n",
              "             9: 267,\n",
              "             10: 111,\n",
              "             11: 214,\n",
              "             12: 21,\n",
              "             13: 120,\n",
              "             14: 50})"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sents_idx = nlargest(4, ranking, key=ranking.get)\n",
        "sents_idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu00wDNKHliZ",
        "outputId": "20878d04-5838-4720-be88-63c0c93fbb0b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9, 11, 5, 13]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted(sents_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvsjuohpHrt7",
        "outputId": "dbb0e678-d183-484a-c4ba-ec216def7572"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 9, 11, 13]"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[sents[j] for j in sorted(sents_idx)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhaDozxeHtl8",
        "outputId": "1c052001-d78e-41dd-a500-bd899fee3491"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['On Tuesday, the Defense Department took another significant step toward monitoring all of the cosmic junk swirling around in space, by delivering a gigantic new telescope capable of seeing small objects from very far away.Developed by the Defense Advanced Research Project Agency, the Space Surveillance Telescope was formally transferred to the Air Force during a ceremony at White Sands Missile Base in New Mexico Tuesday.AdvertisementStory continues below advertisementThe telescope is designed to monitor objects as small as softballs, in Geosynchonous orbit (GEO)—some of the most important real estate in space.',\n",
              " \"But the telescope's ability to see “something very far away over a very wide area is really what it’s best at.”DARPA says the advanced technology in the massive, 90-ton telescope would allow officials to go from “seeing only a few large objects at a time through the equivalent of a drinking straw to a windshield view with 10,000 objects at a time.” It is also being used by NASA to monitor asteroids and other near-Earth objects that could collide with the planet, officials said.AdvertisementStory continues below advertisementOver the next two years, the telescope is going to be moved and reconstructed in Australia, a vantage point that would allow it to survey an under served area of space.The telescope is “a big improvement over the legacy ground-based optical telescopes that are used by the U.S. Air Force, because it can search large areas of sky and also track very faint (small) objects in and around GEO,” Brian Weeden, a Technical Advisor at the Secure World Foundation, wrote in an email.\",\n",
              " 'The radar system is going to be located on Kwajalein Atoll in the Marshall Islands and would use radar to help the Air Force track 10 times amount of debris than it currently monitors.AdvertisementStory continues below advertisementWith many valuable assets in space—satellites used for intelligence, communications and guiding weapons—the Pentagon has become increasingly concerned with what it calls “space situational awareness.” Instead of being a benign environment, the Pentagon likes to say that space has become “contested, congested and competitive.” In orbit, debris moves very fast, as much as 17,500 m.p.h., so that even a fleck of paint could cause damage.In 2007, the Chinese fired a missile that blew up a dead satellite and littered space with thousands of pieces of debris.',\n",
              " 'It has plans to send swarms of small satellites into orbit that are more difficult to target.“Every military operation that takes place in the world today is critically dependent on space in one way or another,” Air Force Gen. John Hyten said in an interview earlier this year when he was the commander of the Air Force Space Command.']"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DEMO\n",
        "\n",
        "import sklearn\n",
        "\n",
        "print(sklearn.__version__)\n",
        "\n",
        "\n",
        "train_text = [\n",
        "              \"Be yourself; everyone else is already taken.\",\n",
        "              \"A room without books is like a body without a soul.\",\n",
        "              \"Be the change that you wish to see in the world.\",\n",
        "              \"If you tell the truth, you don't have to remember anything.\",\n",
        "              \"Always forgive your enemies; nothing annoys them so much.\"\n",
        "             ]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAZ0VWzoZUQq",
        "outputId": "641ddf3a-7853-41ff-86b3-5d893196af87"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CountVectorizer\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count_vectorizer = CountVectorizer()"
      ],
      "metadata": {
        "id": "Htul-1BqHxoK"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_vectorizer.fit(train_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-L2crbEZZK_E",
        "outputId": "22cc518b-9143-45d1-be74-f064cf1c0a25"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer()"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_vectorizer.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yI7_gMXbZZl6",
        "outputId": "24f4ff1d-00c7-4d97-b537-d547ff639eaa"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'already': 0,\n",
              " 'always': 1,\n",
              " 'annoys': 2,\n",
              " 'anything': 3,\n",
              " 'be': 4,\n",
              " 'body': 5,\n",
              " 'books': 6,\n",
              " 'change': 7,\n",
              " 'don': 8,\n",
              " 'else': 9,\n",
              " 'enemies': 10,\n",
              " 'everyone': 11,\n",
              " 'forgive': 12,\n",
              " 'have': 13,\n",
              " 'if': 14,\n",
              " 'in': 15,\n",
              " 'is': 16,\n",
              " 'like': 17,\n",
              " 'much': 18,\n",
              " 'nothing': 19,\n",
              " 'remember': 20,\n",
              " 'room': 21,\n",
              " 'see': 22,\n",
              " 'so': 23,\n",
              " 'soul': 24,\n",
              " 'taken': 25,\n",
              " 'tell': 26,\n",
              " 'that': 27,\n",
              " 'the': 28,\n",
              " 'them': 29,\n",
              " 'to': 30,\n",
              " 'truth': 31,\n",
              " 'wish': 32,\n",
              " 'without': 33,\n",
              " 'world': 34,\n",
              " 'you': 35,\n",
              " 'your': 36,\n",
              " 'yourself': 37}"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_vectorizer.vocabulary_.get('truth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3wA1XY_ZeSm",
        "outputId": "1eda6aa8-d073-4cab-8ed4-4cd93c480b0c"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_vector = count_vectorizer.transform(train_text)"
      ],
      "metadata": {
        "id": "V7w-2RbTZh8C"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(transformed_vector.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fg9Sbi4ZnSC",
        "outputId": "2e52681b-d4f3-4dee-d307-4941ceed6fd8"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 38)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(transformed_vector.toarray())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1xYialBZpWT",
        "outputId": "06b00ea1-23c2-4afd-d350-44c104b147e2"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
            "  0 1]\n",
            " [0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 2 0 0\n",
            "  0 0]\n",
            " [0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 1 2 0 1 0 1 0 1 1\n",
            "  0 0]\n",
            " [0 0 0 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 1 1 0 0 0 2\n",
            "  0 0]\n",
            " [0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0\n",
            "  1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_text = [\"Don't cry because it's over, smile because it happened.\"]\n",
        "\n",
        "count_vectorizer.transform(test_text).toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "It9Lgm4kZsZk",
        "outputId": "069be337-ba07-4b35-de24-81c1cf29d900"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_vectorizer.fit(train_text + test_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmBU_hzvZwgk",
        "outputId": "2a77f637-dbd6-4cd0-81e0-cdcf806bb0bd"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer()"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(count_vectorizer.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dprMO-peZzd9",
        "outputId": "543a564f-1a64-4bb1-f927-bd42796b0cc8"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'be': 4, 'yourself': 43, 'everyone': 13, 'else': 11, 'is': 19, 'already': 0, 'taken': 31, 'room': 26, 'without': 39, 'books': 7, 'like': 21, 'body': 6, 'soul': 30, 'the': 34, 'change': 8, 'that': 33, 'you': 41, 'wish': 38, 'to': 36, 'see': 27, 'in': 18, 'world': 40, 'if': 17, 'tell': 32, 'truth': 37, 'don': 10, 'have': 16, 'remember': 25, 'anything': 3, 'always': 1, 'forgive': 14, 'your': 42, 'enemies': 12, 'nothing': 23, 'annoys': 2, 'them': 35, 'so': 29, 'much': 22, 'cry': 9, 'because': 5, 'it': 20, 'over': 24, 'smile': 28, 'happened': 15}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_vectorizer.transform(test_text).toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hcedj6vZ4yb",
        "outputId": "d3f311e2-0d6e-4756-a7ba-6d8386ff5004"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0,\n",
              "        0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: this will produce incorrect output if you launch it after you fit() on train_text + test_text\n",
        "count_vectorizer.inverse_transform(transformed_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8MVwBvjZ72U",
        "outputId": "86e30159-3178-4583-fab1-afb9d59bc96d"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array(['already', 'be', 'cry', 'else', 'have', 'remember', 'truth'],\n",
              "       dtype='<U8'),\n",
              " array(['because', 'body', 'have', 'if', 'like', 'over', 'that'],\n",
              "       dtype='<U8'),\n",
              " array(['be', 'books', 'happened', 'much', 'see', 'smile', 'soul', 'tell',\n",
              "        'the', 'them'], dtype='<U8'),\n",
              " array(['anything', 'change', 'everyone', 'forgive', 'it', 'room', 'smile',\n",
              "        'soul', 'taken', 'them'], dtype='<U8'),\n",
              " array(['always', 'annoys', 'don', 'enemies', 'in', 'is', 'nothing', 'so',\n",
              "        'to'], dtype='<U8')]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_gram_vectorizer = CountVectorizer(ngram_range=(2, 2))"
      ],
      "metadata": {
        "id": "Q-7wyeQIaH70"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_vector = n_gram_vectorizer.fit_transform(train_text)\n",
        "\n",
        "transformed_vector.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbsIR-uQaJPg",
        "outputId": "5a3ed09b-8f1f-43c0-99bb-62057fa2ae1d"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 41)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transformed_vector.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPN7PAMUaRJ0",
        "outputId": "9a0c2b7c-0080-41b2-abdb-be6dd16ba10c"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "        1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
              "        0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0],\n",
              "       [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "        0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_gram_vectorizer.inverse_transform(transformed_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hP86oPZeaVQ6",
        "outputId": "dbb966e8-b46e-41e6-a5fd-2209886d6483"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array(['be yourself', 'yourself everyone', 'everyone else', 'else is',\n",
              "        'is already', 'already taken'], dtype='<U17'),\n",
              " array(['room without', 'without books', 'books is', 'is like',\n",
              "        'like body', 'body without', 'without soul'], dtype='<U17'),\n",
              " array(['be the', 'the change', 'change that', 'that you', 'you wish',\n",
              "        'wish to', 'to see', 'see in', 'in the', 'the world'], dtype='<U17'),\n",
              " array(['if you', 'you tell', 'tell the', 'the truth', 'truth you',\n",
              "        'you don', 'don have', 'have to', 'to remember',\n",
              "        'remember anything'], dtype='<U17'),\n",
              " array(['always forgive', 'forgive your', 'your enemies',\n",
              "        'enemies nothing', 'nothing annoys', 'annoys them', 'them so',\n",
              "        'so much'], dtype='<U17')]"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TfidfVectorizer\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "tfidf_vector = tfidf_vectorizer.fit_transform(train_text)\n",
        "\n",
        "tfidf_vectorizer.vocabulary_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2YeLNcB0aZh0",
        "outputId": "86311b34-f065-4b78-e949-bb2d29fe715d"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'already': 0,\n",
              " 'always': 1,\n",
              " 'annoys': 2,\n",
              " 'anything': 3,\n",
              " 'be': 4,\n",
              " 'body': 5,\n",
              " 'books': 6,\n",
              " 'change': 7,\n",
              " 'don': 8,\n",
              " 'else': 9,\n",
              " 'enemies': 10,\n",
              " 'everyone': 11,\n",
              " 'forgive': 12,\n",
              " 'have': 13,\n",
              " 'if': 14,\n",
              " 'in': 15,\n",
              " 'is': 16,\n",
              " 'like': 17,\n",
              " 'much': 18,\n",
              " 'nothing': 19,\n",
              " 'remember': 20,\n",
              " 'room': 21,\n",
              " 'see': 22,\n",
              " 'so': 23,\n",
              " 'soul': 24,\n",
              " 'taken': 25,\n",
              " 'tell': 26,\n",
              " 'that': 27,\n",
              " 'the': 28,\n",
              " 'them': 29,\n",
              " 'to': 30,\n",
              " 'truth': 31,\n",
              " 'wish': 32,\n",
              " 'without': 33,\n",
              " 'world': 34,\n",
              " 'you': 35,\n",
              " 'your': 36,\n",
              " 'yourself': 37}"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vector.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcY3owesahyb",
        "outputId": "243e0992-5c35-4b7f-c51f-8f1729e72633"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 38)"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vector.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "po4RC_CEalFe",
        "outputId": "79adefcc-46f3-46d6-c859-719c5b817851"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.39835162, 0.        , 0.        , 0.        , 0.32138758,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.39835162,\n",
              "        0.        , 0.39835162, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.32138758, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.39835162, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.39835162],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.32189611, 0.32189611, 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.25970376, 0.32189611, 0.        , 0.        ,\n",
              "        0.        , 0.32189611, 0.        , 0.        , 0.32189611,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.64379222, 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.24831578,\n",
              "        0.        , 0.        , 0.30778101, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.30778101, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.30778101, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.30778101, 0.49663156, 0.        ,\n",
              "        0.24831578, 0.        , 0.30778101, 0.        , 0.30778101,\n",
              "        0.24831578, 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.30281493, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.30281493, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.30281493, 0.30281493,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.30281493, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.30281493, 0.        , 0.24430918, 0.        ,\n",
              "        0.24430918, 0.30281493, 0.        , 0.        , 0.        ,\n",
              "        0.48861835, 0.        , 0.        ],\n",
              "       [0.        , 0.33333333, 0.33333333, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.33333333, 0.        , 0.33333333, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.33333333, 0.33333333,\n",
              "        0.        , 0.        , 0.        , 0.33333333, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.33333333,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.33333333, 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer.idf_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Z18cQIoasR0",
        "outputId": "cedae7da-6f19-44b4-d102-d6b935df7a5f"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.09861229, 2.09861229, 2.09861229, 2.09861229, 1.69314718,\n",
              "       2.09861229, 2.09861229, 2.09861229, 2.09861229, 2.09861229,\n",
              "       2.09861229, 2.09861229, 2.09861229, 2.09861229, 2.09861229,\n",
              "       2.09861229, 1.69314718, 2.09861229, 2.09861229, 2.09861229,\n",
              "       2.09861229, 2.09861229, 2.09861229, 2.09861229, 2.09861229,\n",
              "       2.09861229, 2.09861229, 2.09861229, 1.69314718, 2.09861229,\n",
              "       1.69314718, 2.09861229, 2.09861229, 2.09861229, 2.09861229,\n",
              "       1.69314718, 2.09861229, 2.09861229])"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict(zip(tfidf_vectorizer.get_feature_names(), tfidf_vectorizer.idf_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8pq47JSatkz",
        "outputId": "e5e531ec-20d0-4d73-d518-ec15abebb5e2"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'already': 2.09861228866811,\n",
              " 'always': 2.09861228866811,\n",
              " 'annoys': 2.09861228866811,\n",
              " 'anything': 2.09861228866811,\n",
              " 'be': 1.6931471805599454,\n",
              " 'body': 2.09861228866811,\n",
              " 'books': 2.09861228866811,\n",
              " 'change': 2.09861228866811,\n",
              " 'don': 2.09861228866811,\n",
              " 'else': 2.09861228866811,\n",
              " 'enemies': 2.09861228866811,\n",
              " 'everyone': 2.09861228866811,\n",
              " 'forgive': 2.09861228866811,\n",
              " 'have': 2.09861228866811,\n",
              " 'if': 2.09861228866811,\n",
              " 'in': 2.09861228866811,\n",
              " 'is': 1.6931471805599454,\n",
              " 'like': 2.09861228866811,\n",
              " 'much': 2.09861228866811,\n",
              " 'nothing': 2.09861228866811,\n",
              " 'remember': 2.09861228866811,\n",
              " 'room': 2.09861228866811,\n",
              " 'see': 2.09861228866811,\n",
              " 'so': 2.09861228866811,\n",
              " 'soul': 2.09861228866811,\n",
              " 'taken': 2.09861228866811,\n",
              " 'tell': 2.09861228866811,\n",
              " 'that': 2.09861228866811,\n",
              " 'the': 1.6931471805599454,\n",
              " 'them': 2.09861228866811,\n",
              " 'to': 1.6931471805599454,\n",
              " 'truth': 2.09861228866811,\n",
              " 'wish': 2.09861228866811,\n",
              " 'without': 2.09861228866811,\n",
              " 'world': 2.09861228866811,\n",
              " 'you': 1.6931471805599454,\n",
              " 'your': 2.09861228866811,\n",
              " 'yourself': 2.09861228866811}"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer.inverse_transform(tfidf_vector)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiR9VzVpazlD",
        "outputId": "69e3b993-2c79-4fdd-abb0-00cf3cd8762a"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array(['taken', 'already', 'is', 'else', 'everyone', 'yourself', 'be'],\n",
              "       dtype='<U8'),\n",
              " array(['soul', 'body', 'like', 'books', 'without', 'room', 'is'],\n",
              "       dtype='<U8'),\n",
              " array(['world', 'in', 'see', 'to', 'wish', 'you', 'that', 'change', 'the',\n",
              "        'be'], dtype='<U8'),\n",
              " array(['anything', 'remember', 'have', 'don', 'truth', 'tell', 'if', 'to',\n",
              "        'you', 'the'], dtype='<U8'),\n",
              " array(['much', 'so', 'them', 'annoys', 'nothing', 'enemies', 'your',\n",
              "        'forgive', 'always'], dtype='<U8')]"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# HashingVectorizer\n",
        "\n",
        "from sklearn.feature_extraction.text import HashingVectorizer\n",
        "\n",
        "hashing_vectorizer = HashingVectorizer(n_features=8, norm=None) # you can specify the bucket count and normalization \n",
        "feature_vector = hashing_vectorizer.transform(train_text)\n",
        "\n",
        "feature_vector.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bha7qk-Ba0z3",
        "outputId": "2e0e4185-ef79-46ea-be30-0371af73af41"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_vector.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18lBTOJpa-hM",
        "outputId": "043eb188-7316-4694-b282-14863a6f8882"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.,  0.,  0.,  1.,  1.,  1., -1., -2.],\n",
              "       [ 0.,  2.,  1.,  0.,  0.,  1.,  1., -1.],\n",
              "       [ 0.,  1.,  0.,  2.,  1., -1., -3., -1.],\n",
              "       [ 1.,  2.,  0.,  0.,  2.,  1.,  1.,  0.],\n",
              "       [-2.,  1.,  0.,  0., -1.,  0., -1., -2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    }
  ]
}